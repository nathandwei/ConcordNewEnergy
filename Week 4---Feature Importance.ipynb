{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)\n",
    "\n",
    "def evaluate_prediction(predictions, actual, model_name):\n",
    "    errors = predictions - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    print('MAE: {:.2f}'.format(mae))\n",
    "    print('RMSE: {:.2f}'.format(rmse))\n",
    "    print('')\n",
    "    print('')\n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/ercot_sl_2019_2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sl = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset/ercot_sl_2019_2023.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m sl[\u001b[33m'\u001b[39m\u001b[33msced_time_stamp_local\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(sl[\u001b[33m'\u001b[39m\u001b[33msced_time_stamp_local\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m sl.set_index(\u001b[33m'\u001b[39m\u001b[33msced_time_stamp_local\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ConcordNewEnergy/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ConcordNewEnergy/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ConcordNewEnergy/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ConcordNewEnergy/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ConcordNewEnergy/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset/ercot_sl_2019_2023.csv'"
     ]
    }
   ],
   "source": [
    "sl = pd.read_csv('dataset/ercot_sl_2019_2023.csv')\n",
    "sl['sced_time_stamp_local'] = pd.to_datetime(sl['sced_time_stamp_local'])\n",
    "sl.set_index('sced_time_stamp_local', inplace=True)\n",
    "sl = sl.resample('h').mean()\n",
    "date_range = pd.date_range(start=sl.index.min(), end=sl.index.max(), freq='h')\n",
    "sl = sl[~sl.index.duplicated(keep='first')]\n",
    "sl = sl.reindex(date_range, fill_value=np.nan)\n",
    "sl.interpolate(method='time', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_14692\\3109986249.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dap['timestamp'] = pd.to_datetime(dap['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "dap = pd.read_csv('dataset/hourly_ercot_day_ahead_sl_2019_2023.csv')\n",
    "dap['timestamp'] = pd.to_datetime(dap['timestamp'])\n",
    "dap.set_index('timestamp', inplace=True)\n",
    "date_range = pd.date_range(start=dap.index.min(), end='2024-01-01 23:55:00', freq='h')\n",
    "dap = dap[~dap.index.duplicated(keep='first')]\n",
    "dap = dap.reindex(date_range, fill_value=np.nan)\n",
    "dap.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_tlf = pd.read_csv('dataset/FORECASTED_TLF.csv')\n",
    "forecasted_tlf['datetime'] = pd.to_datetime(forecasted_tlf['datetime'])\n",
    "forecasted_tlf.set_index('datetime', inplace=True)\n",
    "date_range = pd.date_range(start=forecasted_tlf.index.min(), end='2024-01-01 23:55:00', freq='h')\n",
    "forecasted_tlf = forecasted_tlf[~forecasted_tlf.index.duplicated(keep='first')]\n",
    "forecasted_tlf = forecasted_tlf.reindex(date_range, fill_value=np.nan)\n",
    "forecasted_tlf.interpolate(method='time', inplace=True)\n",
    "\n",
    "forecasted_dlf = pd.read_csv('dataset/FORECASTED_DLF.csv')\n",
    "forecasted_dlf['datetime'] = pd.to_datetime(forecasted_dlf['datetime'])\n",
    "forecasted_dlf.set_index('datetime', inplace=True)\n",
    "date_range = pd.date_range(start=forecasted_dlf.index.min(), end='2024-01-01 23:55:00', freq='h')\n",
    "forecasted_dlf = forecasted_dlf[~forecasted_dlf.index.duplicated(keep='first')]\n",
    "forecasted_dlf = forecasted_dlf.reindex(date_range, fill_value=np.nan)\n",
    "forecasted_dlf.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAP</th>\n",
       "      <th>SCED</th>\n",
       "      <th>F_DLF</th>\n",
       "      <th>F_TLF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00</th>\n",
       "      <td>23.9250</td>\n",
       "      <td>26.216109</td>\n",
       "      <td>0.039835</td>\n",
       "      <td>0.016499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 01:00:00</th>\n",
       "      <td>23.3140</td>\n",
       "      <td>25.671136</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 02:00:00</th>\n",
       "      <td>23.3475</td>\n",
       "      <td>24.970952</td>\n",
       "      <td>0.050937</td>\n",
       "      <td>0.016411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 03:00:00</th>\n",
       "      <td>23.0595</td>\n",
       "      <td>24.787712</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 04:00:00</th>\n",
       "      <td>25.2672</td>\n",
       "      <td>24.887786</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.016534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 19:00:00</th>\n",
       "      <td>19.3715</td>\n",
       "      <td>14.422107</td>\n",
       "      <td>0.012525</td>\n",
       "      <td>0.021356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 20:00:00</th>\n",
       "      <td>16.7739</td>\n",
       "      <td>12.597410</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.021367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 21:00:00</th>\n",
       "      <td>15.0035</td>\n",
       "      <td>10.170172</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 22:00:00</th>\n",
       "      <td>15.7699</td>\n",
       "      <td>9.872549</td>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.021408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:00:00</th>\n",
       "      <td>16.2404</td>\n",
       "      <td>12.594126</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.021436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DAP       SCED     F_DLF     F_TLF\n",
       "2019-01-02 00:00:00  23.9250  26.216109  0.039835  0.016499\n",
       "2019-01-02 01:00:00  23.3140  25.671136  0.031644  0.016441\n",
       "2019-01-02 02:00:00  23.3475  24.970952  0.050937  0.016411\n",
       "2019-01-02 03:00:00  23.0595  24.787712  0.015945  0.016441\n",
       "2019-01-02 04:00:00  25.2672  24.887786  0.059952  0.016534\n",
       "...                      ...        ...       ...       ...\n",
       "2023-12-31 19:00:00  19.3715  14.422107  0.012525  0.021356\n",
       "2023-12-31 20:00:00  16.7739  12.597410  0.032945  0.021367\n",
       "2023-12-31 21:00:00  15.0035  10.170172  0.033003  0.021383\n",
       "2023-12-31 22:00:00  15.7699   9.872549  0.027504  0.021408\n",
       "2023-12-31 23:00:00  16.2404  12.594126  0.023490  0.021436\n",
       "\n",
       "[43800 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare the data for training and testing\n",
    "df = pd.concat([dap, sl, forecasted_dlf, forecasted_tlf], axis=1)\n",
    "df.columns = ['DAP', 'SCED', 'F_DLF', 'F_TLF']\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26233, 24, 4) (26233, 24, 1) (8713, 24, 4) (8713, 24, 1) (8713, 24, 4) (8713, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## log transform\n",
    "log_data = df.copy(deep=True)\n",
    "log_data.loc[:,\"SCED\"] = np.log(df.loc[:,\"SCED\"] + 1 - min(df.loc[:,\"SCED\"]))\n",
    "log_data.loc[:,\"DAP\"] = np.log(df.loc[:,\"DAP\"] + 1 - min(df.loc[:,\"DAP\"]))\n",
    "log_data.loc[:,\"F_TLF\"] = np.log(df.loc[:,\"F_TLF\"] + 1 - min(df.loc[:,\"F_TLF\"]))\n",
    "log_data.loc[:,\"F_DLF\"] = np.log(df.loc[:,\"F_DLF\"] + 1 - min(df.loc[:,\"F_DLF\"]))\n",
    "\n",
    "#Shift for prediction\n",
    "df['DAP'] = df['DAP'].shift(-24)\n",
    "\n",
    "# 3 years training, 1 year validation, 1 year testing\n",
    "x_train_df_reg = log_data.loc[:'2021-12-31 23:55:00'].iloc[:,:]\n",
    "x_val_df_reg = log_data.loc['2022-01-01 00:00:00':'2022-12-31 23:55:00'].iloc[:,:]\n",
    "x_test_df_reg = log_data.loc['2023-01-01 00:00:00':].iloc[:,:]\n",
    "\n",
    "# Shift back for target variable\n",
    "df['DAP'] = df['DAP'].shift(24)\n",
    "\n",
    "#Change target variable to DAP\n",
    "y_train_df_reg = log_data.loc[:'2021-12-31 23:55:00'].iloc[:, :1]\n",
    "y_val_df_reg = log_data.loc['2022-01-01 00:00:00':'2022-12-31 23:55:00'].iloc[:, :1]\n",
    "y_test_df_reg = log_data.loc['2023-01-01 00:00:00':].iloc[:, :1]\n",
    "\n",
    "x_train_df_reg.reset_index(drop=True, inplace=True)\n",
    "x_val_df_reg.reset_index(drop=True, inplace=True)\n",
    "x_test_df_reg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Standardization\n",
    "x_mean_reg, x_std_reg = x_train_df_reg.mean(), x_train_df_reg.std()\n",
    "y_mean_reg, y_std_reg = y_train_df_reg.mean(), y_train_df_reg.std()\n",
    "\n",
    "x_std_reg = x_std_reg +0.00001\n",
    "\n",
    "x_train_reg = (x_train_df_reg - x_mean_reg)/x_std_reg\n",
    "x_val_reg = (x_val_df_reg - x_mean_reg)/x_std_reg\n",
    "x_test_reg = (x_test_df_reg - x_mean_reg)/x_std_reg\n",
    "\n",
    "y_train_reg = (y_train_df_reg - y_mean_reg)/y_std_reg\n",
    "y_val_reg = (y_val_df_reg - y_mean_reg)/y_std_reg\n",
    "y_test_reg = (y_test_df_reg - y_mean_reg)/y_std_reg\n",
    "\n",
    "# Shift the data for the lags\n",
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "\n",
    "x_train_lstm = np.array([x_train_reg[i:i+n_steps_in] for i in range(0, x_train_reg.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_train_lstm = np.array([y_train_reg[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train_reg.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "x_val_lstm = np.array([x_val_reg[i:i+n_steps_in] for i in range(0, x_val_reg.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_val_lstm = np.array([y_val_reg[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_val_reg.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "x_test_lstm = np.array([x_test_reg[i:i+n_steps_in] for i in range(0, x_test_reg.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_test_lstm = np.array([y_test_reg[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test_reg.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "print(x_train_lstm.shape,y_train_lstm.shape,x_val_lstm.shape,y_val_lstm.shape, x_test_lstm.shape,y_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\OneDrive\\Documents\\ConcordNewEnergy\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m17,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m1,560\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,408</span> (220.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,408\u001b[0m (220.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,408</span> (220.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,408\u001b[0m (220.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 1.1463 - val_loss: 0.9008\n",
      "Epoch 2/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 8.3420 - val_loss: 1.2368\n",
      "Epoch 3/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 1.0539 - val_loss: 0.9049\n",
      "Epoch 4/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.6326 - val_loss: 0.8387\n",
      "Epoch 5/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5548 - val_loss: 7.0412\n",
      "Epoch 6/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 1.1530 - val_loss: 0.8628\n",
      "Epoch 7/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.6495 - val_loss: 0.8247\n",
      "Epoch 8/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5364 - val_loss: 0.7864\n",
      "Epoch 9/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4998 - val_loss: 0.7278\n",
      "Epoch 10/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5187 - val_loss: 0.7204\n",
      "Epoch 11/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4636 - val_loss: 0.6344\n",
      "Epoch 12/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3969 - val_loss: 0.5604\n",
      "Epoch 13/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3959 - val_loss: 0.6163\n",
      "Epoch 14/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3485 - val_loss: 0.5491\n",
      "Epoch 15/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.6312 - val_loss: 0.6520\n",
      "Epoch 16/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4563 - val_loss: 0.5883\n",
      "Epoch 17/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4100 - val_loss: 0.4951\n",
      "Epoch 18/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3813 - val_loss: 0.5192\n",
      "Epoch 19/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3346 - val_loss: 0.5199\n",
      "Epoch 20/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2789 - val_loss: 0.5215\n",
      "Epoch 21/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3548 - val_loss: 0.4374\n",
      "Epoch 22/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2737 - val_loss: 0.4391\n",
      "Epoch 23/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.2131 - val_loss: 0.4193\n",
      "Epoch 24/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2330 - val_loss: 0.4418\n",
      "Epoch 25/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2282 - val_loss: 0.4920\n",
      "Epoch 26/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3497 - val_loss: 0.4919\n",
      "Epoch 27/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2805 - val_loss: 0.5018\n",
      "Epoch 28/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2126 - val_loss: 0.4380\n",
      "Epoch 29/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2331 - val_loss: 0.6003\n",
      "Epoch 30/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2312 - val_loss: 0.4913\n",
      "Epoch 31/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.2630 - val_loss: 0.5329\n",
      "Epoch 32/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.1787 - val_loss: 0.4579\n",
      "Epoch 33/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1910 - val_loss: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "n_neurons  = 64  # number of neurons in the Dense layer\n",
    "activation     = 'relu' # activation function\n",
    "learning_rate  = 0.0005\n",
    "minibatch_size = 64\n",
    "num_epochs     = 50\n",
    "\n",
    "# MLP model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(n_neurons,input_shape=(x_train_lstm.shape[1],x_train_lstm.shape[2]),\n",
    "               return_sequences=True,activation=activation))\n",
    "lstm_model.add(LSTM(n_neurons,return_sequences=False,\n",
    "               activation=activation))\n",
    "lstm_model.add(Dense(n_neurons,activation=activation))\n",
    "lstm_model.add(Dense(y_train_lstm.shape[-2],activation='linear')) \n",
    "\n",
    "lstm_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = lstm_model.fit(x_train_lstm, y_train_lstm, \n",
    "                        validation_data = (x_val_lstm, y_val_lstm), \n",
    "                        batch_size = minibatch_size,\n",
    "                        epochs = num_epochs,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stop],\n",
    "                        shuffle=False)\n",
    "\n",
    "# saving trained model\n",
    "model_path = os.path.join(cwd,'saved_model')\n",
    "make_dir(model_path)\n",
    "lstm_model.save(os.path.join(model_path,'DAP_Model_Week_3.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "MAE: 0.56\n",
      "RMSE: 1.00\n",
      "\n",
      "\n",
      "MAE: 46.80\n",
      "RMSE: 212.82\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(46.80489923633535), np.float64(212.8179825511515))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload the saved model\n",
    "model_path = os.path.join(cwd,'saved_model')\n",
    "lstm_model = load_model(\n",
    "    os.path.join(model_path, 'DAP_Model_Week_3.h5'),\n",
    "    custom_objects={'mse': MeanSquaredError()}\n",
    ")\n",
    "\n",
    "# Make prediciton\n",
    "y_test_pred = lstm_model.predict(x_test_lstm)\n",
    "\n",
    "# Evaluate Prediction\n",
    "evaluate_prediction(y_test_pred , y_test_lstm[:,:,0], 'lstm')\n",
    "\n",
    "# Rescale to get values before normalization\n",
    "y_test_pred_rescale = y_test_pred*y_std_reg.values + y_mean_reg.values\n",
    "y_test_lstm_rescale = y_test_lstm*y_std_reg.values + y_mean_reg.values\n",
    "\n",
    "# inverse log to get prices in the actual scale\n",
    "y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(df.loc[:,\"SCED\"])\n",
    "y_test_lstm_invlog = np.exp(y_test_lstm_rescale) -1 + min(df.loc[:,\"SCED\"])\n",
    "\n",
    "# revaluation after the rescaling\n",
    "evaluate_prediction(y_test_pred_invlog , y_test_lstm_invlog[:,:,0], 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
